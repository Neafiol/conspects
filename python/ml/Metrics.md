Classifiter metrics
====

## F1 Score:
* precision - % верных из угаданных
* recall - % найднных верных

$$\large F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{(\beta^2 \cdot \mathrm{precision}) + \mathrm{recall}}.$$

![alt text](src/f1.png)


-----------------------

## Accuracy:
 Самый простой вариант: % верных ответов
$$\large accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$


-----------------------

## Коэффициент детерминации
Доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью.
$$\large R^2 = 1 - \frac{RSS}{TSS} =  1 - \frac{\sum_{t=1}^n(y_t - f(x_t))^2}{\sum_{t=1}^n(y_t - y_{mean})^2}$$

## AUC-ROC
Построим график в системе координат
* True Positive Rate (TPR) - % верно захваченной области
* False Positive Rate (FPR) - % на который залезли не туда

Площадь под этим графиком и будет нашей точностью, двигаемся каждый раз в направлении полученном при подстановке в формулы значения для нашей точки.

$$\large TPR = \frac{TP}{TP + FN} \;\;\;\;\;  FPR = \frac{FP}{FP + TN}$$


## Logistic Loss
Данная метрика нечасто выступает в бизнес-требованиях, но часто — в задачах на kaggle.
Интуитивно можно представить минимизацию logloss как задачу максимизации accuracy путем штрафа за неверные предсказания. Однако необходимо отметить, что logloss крайне сильно штрафует за уверенность классификатора в неверном ответе.

$$\large logloss = - \frac{1}{l} \cdot \sum_{i=1}^l (y_i \cdot log(\hat y_i) + (1 - y_i) \cdot log(1 - \hat y_i))$$


Regression metrics
==================

## Mean Absolute Error (MAE)
Метрика измеряет среднюю сумму абсолютной разницы между фактическим значением и прогнозируемым значением.

$$\large MAE = \frac{1}{l} \cdot \sum_{i=1}^l |y_i -y|$$

## Mean Squared Error (MSE)
Измеряет среднюю сумму квадратной разности между фактическим значением и прогнозируемым значением для всех точек данных. Выполняется возведение во вторую степень, поэтому отрицательные значения не компенсируют положительными.

* Она подчеркивает большие ошибки над меньших ошибках.
* Является дифференцируемым, что позволяет более эффективно         использовать для поиска минимальных или максимальных значений с помощью математических методов.

$$\large MSE = \frac{1}{l} \cdot \sum_{i=1}^l (y_i -y)^2$$

## Root Mean Squared Error (RMSE)

* Ее легко интерпретировать, поскольку он имеет те же единицы, что и исходные значения (в отличие от MSE). 
* Она оперирует меньшими величинами по абсолютному значению, что может быть полезно для вычисления на компьютере.
